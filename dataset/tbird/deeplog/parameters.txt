model_name: deeplog
dataset_name: tbird
device: cpu
data_dir: ./dataset/tbird/
output_dir: dataset/tbird/
run_dir: runs/2023-03-19_thunder_sample
folder: tbird/
log_file: sample_log_file.log
sample_size: 1000000
sample_log_file: sample_log_file.log
parser_type: drain
log_format: <Label> <Timestamp> <Date> <Node> <Luna> <Ziua> <Time> <NodeRepeat> <Type> <Component> <Level> <Content>
regex: []
keep_para: False
st: 0.3
depth: 3
max_child: 100
tau: 0.5
is_process: True
is_instance: False
train_file: train_fixed100_instances.pkl
test_file: test_fixed100_instances.pkl
window_type: sliding
session_level: hour
window_size: 0.2
step_size: 0.2
train_size: 0.8
train_ratio: 1.0
valid_ratio: 0.1
test_ratio: 1.0
max_epoch: 10
n_epochs_stop: 10
n_warm_up_epoch: 0
batch_size: 1024
lr: 0.001
is_logkey: True
random_sample: False
is_time: False
min_freq: 1
seq_len: 10
min_len: 10
max_len: 512
mask_ratio: 0.5
adaptive_window: False
deepsvdd_loss: False
deepsvdd_loss_test: False
scale: None
hidden: 256
layers: 4
attn_heads: 4
num_workers: 5
adam_beta1: 0.9
adam_beta2: 0.999
adam_weight_decay: 0.0
sample: sliding_window
history_size: 10
embeddings: embeddings.json
sequentials: True
quantitatives: True
semantics: False
parameters: False
input_size: 1
hidden_size: 128
num_layers: 2
embedding_dim: 50
accumulation_step: 5
optimizer: adam
lr_decay_ratio: 0.1
num_candidates: 150
log_freq: 100
resume_path: False
num_encoder_layers: 1
num_decoder_layers: 1
dim_model: 300
num_heads: 8
dim_feedforward: 2048
transformers_dropout: 0.1
model_dir: dataset/tbird/deeplog/
train_vocab: dataset/tbird/train.pkl
vocab_path: dataset/tbird/deeplog_vocab.pkl
model_path: dataset/tbird/deeplog/deeplog.pth
scale_path: dataset/tbird/deeplog/scale.pkl
